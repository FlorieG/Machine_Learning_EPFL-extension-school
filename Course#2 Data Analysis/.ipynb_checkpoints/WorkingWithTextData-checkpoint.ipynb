{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe67a5c-4519-4ec5-b0fd-b986102cda26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s1114237\\OneDrive - Syngenta\\Formations\\Training\\EPFL extension school\\Machine_Learning_EPFL-extension-school\\Course#2 Data Analysis\n"
     ]
    }
   ],
   "source": [
    "#TO remove :\n",
    "import os\n",
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae37d05e-698a-4bd5-b485-d2c39cf3735d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Machine_Learning_EPFL-extension-school\\\\Course#2 Data Analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10216\\3623683747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Machine_Learning_EPFL-extension-school\\Course#2 Data Analysis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Machine_Learning_EPFL-extension-school\\\\Course#2 Data Analysis'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"Machine_Learning_EPFL-extension-school\\Course#2 Data Analysis\")\n",
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef813cc-d05a-455a-9ed3-ab3fbc525383",
   "metadata": {},
   "source": [
    "# Working with text Data\n",
    "## Pandas string functions\n",
    "\n",
    "Textual data can often be messy and difficult to work with since it is usually not in a standardized format ready for analysis. In order to understand how to work with textual data, we must begin by understanding how to work with strings in pandas. String functions in pandas are similar to built-in string functions from Python which we saw in the first course.\n",
    "\n",
    "You might wonder, why we need to bother with string functions from pandas and not just use the Python standard ones? The reason is that Python’s string functions are for individual string objects, while the pandas functions are for Series and DataFrames. So you can think of the pandas string functions as an extension that allows us to operate on an entire Series or DataFrame of strings. As most of the time, the text data that we will be working with will already be in the form of a Series or a DataFrame, so using the specific functions from pandas will make our life a lot easier.\n",
    "\n",
    "So how exactly do we use pandas string functions?\n",
    "\n",
    "''' For pandas Series the string functions are accessed using the str attribute.\n",
    "They have the following general form: Series.str.<function/property>\n",
    "with the function names matching the corresponding string functions in Python.\n",
    "You can find a full list of available functions here.\n",
    "\n",
    "Note: The str attribute is not defined for the pandas DataFrame, only for Series. We must apply any string function column-wise. ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d63068-9ae7-4d24-94c8-1a92532b8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9524bb-0104-4163-8528-a53f2b973476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(\n",
    "    [\n",
    "        \"0\",\n",
    "        \"John Wood\",\n",
    "        \"Colin Welsh\",\n",
    "        \"my list\",\n",
    "        \"02456\",\n",
    "        np.nan,\n",
    "        \"HELLO WORLD\",\n",
    "        \"water%\",\n",
    "    ]\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e784d5d-fcbe-46b1-9633-eb0e937f58ba",
   "metadata": {},
   "source": [
    "Here, we defined a Series of different string objects. If you recall from the first course, the python function str.lower() takes as input a string object and converts it to lowercase. Similarly, the pandas function str.lower() takes as input a Series and converts all strings in this Series to lowercase. Let’s give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe606cab-8a61-451a-b94e-fd6c178da1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      john wood\n",
       "2    colin welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    hello world\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e7791-ede6-41e2-9d78-efaa7860c200",
   "metadata": {},
   "source": [
    "The function str.upper() is the opposite of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12a5d44-0bf9-4b18-8892-fbc5925df848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      JOHN WOOD\n",
       "2    COLIN WELSH\n",
       "3        MY LIST\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         WATER%\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc2c96-1d87-42ee-bb52-60553a16561b",
   "metadata": {},
   "source": [
    "We can get the length of each string in the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d7134d-7ff0-4f4a-a1af-49c9f2d6465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     9.0\n",
       "2    11.0\n",
       "3     7.0\n",
       "4     5.0\n",
       "5     NaN\n",
       "6    11.0\n",
       "7     6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46123301-346f-46e0-9031-2956997ca92e",
   "metadata": {},
   "source": [
    "For data cleaning and manipulations, we will be especially interested in splitting, stripping and replacing strings. Let’s give these a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db34e1c-c67c-441b-9d26-34f811f9630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [0]\n",
       "1      [John, Wood]\n",
       "2    [Colin, Welsh]\n",
       "3        [my, list]\n",
       "4           [02456]\n",
       "5               NaN\n",
       "6    [HELLO, WORLD]\n",
       "7          [water%]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada20f14-3641-4536-8723-447b66f80000",
   "metadata": {},
   "source": [
    "The function str.split() splits each string in the Series on the character provided inside the quotation marks. In our case, we asked the string to be split on the space character. Note that the function returns a Series of lists, where each list contains the substrings that were obtained by splitting on the given character(s). So for example, since the first string '0' did not contain the space character, the list contains a single string which is this original string. On the other hand, the string 'John Wood' was split into two strings. A nice feature of the str.split() function is that we can choose to have the results returned to us in a DataFrame instead of a Series of lists. We do this by including the expand=True parameter as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24852bd6-3099-4ec3-a475-77acb8396043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colin</td>\n",
       "      <td>Welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02456</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HELLO</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>water%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0       0   None\n",
       "1    John   Wood\n",
       "2   Colin  Welsh\n",
       "3      my   list\n",
       "4   02456   None\n",
       "5     NaN    NaN\n",
       "6   HELLO  WORLD\n",
       "7  water%   None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrings = s.str.split(\" \", expand=True)\n",
    "substrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d2e70-b26a-43a8-8845-9aa60b2f9ae5",
   "metadata": {},
   "source": [
    "Note that the number of columns is determined by the maximum size of the lists. In our case, we had lists of size one and two so the DataFrame has two columns. For strings that were not split pandas filled the second column of the DataFrame contains the entry 'None'. We can now easily access the substring by just indexing the DataFrame. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c85358-8895-409a-854d-6ef7bd8e155e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     Wood\n",
       "2    Welsh\n",
       "3     list\n",
       "4     None\n",
       "5      NaN\n",
       "6    WORLD\n",
       "7     None\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrings[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcbe9d-50d5-432e-9d2e-58700a254465",
   "metadata": {},
   "source": [
    "Let’s now look at replacing a substring. The general syntax of the function is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b512d370-7ddb-44af-91df-ed9d47994510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 0\n",
       "1         John Wood\n",
       "2       Colin Welsh\n",
       "3           my list\n",
       "4             02456\n",
       "5               NaN\n",
       "6       HELLO WORLD\n",
       "7    water percent \n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.replace(\"%\", \" percent \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb30c9-a311-42e3-b53d-1095818576f8",
   "metadata": {},
   "source": [
    "If instead we just want to remove a specific substring or character we can use the function str.replace() and choose to replace it with the empty string. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f81be82-eecd-4824-a4d1-b8e0dd3f425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7          water\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.replace(\"%\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065e67d-040b-4441-b97c-37ea9f5dd7ae",
   "metadata": {},
   "source": [
    "Another useful function for us will be to index a particular slice of each string. For example suppose we want to get the first two characters of every string. We can do this by using the index directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1814965c-d93f-4e6d-b507-dbdf4b80079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     Jo\n",
       "2     Co\n",
       "3     my\n",
       "4     02\n",
       "5    NaN\n",
       "6     HE\n",
       "7     wa\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "097a46c2-d9e7-451a-b59a-0a0e06317ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     Jo\n",
       "2     Co\n",
       "3     my\n",
       "4     02\n",
       "5    NaN\n",
       "6     HE\n",
       "7     wa\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.slice(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea4448-1366-4f3c-b9a8-b693f299394f",
   "metadata": {},
   "source": [
    "We can even combine the action of slicing and replacing using the str.slice_replace() function. Here we must mention first the slice of the string that we want to be replaced and then what we want it replaced by. The general syntax looks like this :\n",
    "***This command takes the substring at positions i to j-1 and replaces it with the string 'str'. Let’s give it a try***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a055f9a-ce27-40c4-a868-927835e1586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             ___\n",
       "1      ___hn Wood\n",
       "2    ___lin Welsh\n",
       "3        ___ list\n",
       "4          ___456\n",
       "5             NaN\n",
       "6    ___LLO WORLD\n",
       "7         ___ter%\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.slice_replace(i,j,'str')\n",
    "s.str.slice_replace(0, 2, \"___\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f0a85-df44-4414-97c9-0e21303575ba",
   "metadata": {},
   "source": [
    "A common operation when working with text data is to test whether character strings contain a certain substring or pattern of characters. For instance, if we were only interested in posts about Andrew Wiggins, we’d need to match all posts that make mention of him and avoid matching posts that don’t mention him.\n",
    "\n",
    "Another function that we want to draw your attention to is the str.contains(). When working with text data it is quite common to test whether a certain substring or pattern is present in the strings of our dataset. This can also be useful if we want to obtain all the entries of a dataset that contain some keyword. The str.contains() function returns a Series of True/False values that indicate whether each string contains the given keyword. We can then use this Series of booleans to index our original Series and obtain those entries which correspond to the True values.\n",
    "\n",
    "Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa6e93f-e3f4-4316-97a8-2318564636f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = s.str.contains(\"0\")\n",
    "flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f58021-fcf8-4df7-8e08-9df8448d828a",
   "metadata": {},
   "source": [
    "Note that the NaN entry returned NaN. If we wanted to make sure that we get back a Series of only True and False values we could use the parameter na=False which replaces NaN with a False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "195288c1-c5f5-4f75-b1ad-1042c75babe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = s.str.contains(\"0\", na=False)\n",
    "flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e87fad-9363-43e3-b5f3-5e8a7c4d92d2",
   "metadata": {},
   "source": [
    "Let’s now get back the entries which contain the character '0':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7fa5f8e-a3e0-4078-9253-c1d708c7499f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac3839-2dd7-44d9-909a-b7e8f3bb8227",
   "metadata": {},
   "source": [
    "This concludes our overview of string functions in pandas. For a full list the functions available for us and their descriptions you can consult the pandas documentation Working with text data.\n",
    "\n",
    "## Example : cleaning up the movies dataset\n",
    "\n",
    "Now that we have gotten an overview of the string functions available to us in pandas, it is time we put them to use with a real dataset. To do this we will use a dataset that you have seen before Kaggle TMDB 5000 Movie DataSet. You can download the csv file from the Resources tab and save it in your working directory.\n",
    "\n",
    "Let’s load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a3a3f14-f3ce-43d9-a214-52d8100213ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "movies = pd.read_csv(\"Ressources/c2_tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6651bf-31ae-4140-b0f6-4bc8c866271f",
   "metadata": {},
   "source": [
    "As we will focus on applying pandas string functions, let’s take a look at the first 5 rows of the first 3 text-based columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a7ae3f3-e7a4-4d4d-8df6-1c42974fb9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage  \\\n",
       "0                   http://www.avatarmovie.com/   \n",
       "1  http://disney.go.com/disneypictures/pirates/   \n",
       "2   http://www.sonypictures.com/movies/spectre/   \n",
       "3            http://www.thedarkknightrises.com/   \n",
       "4          http://movies.disney.com/john-carter   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...  \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...  \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...  \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...  \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top entries of the first 3 text-based columns\n",
    "movies.select_dtypes(\"object\").iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf238a3-f3c9-43d3-8b04-8698f05cccc8",
   "metadata": {},
   "source": [
    "As you can see the data is quite messy. Let’s focus on the column genres, as the entries here look particularly difficult to work with. We start by defining a Series corresponding to this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed39f64-fb47-402e-82e5-3b415a146b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = movies[\"genres\"]\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1b8c4-5f94-434f-a56c-5fc37bff851b",
   "metadata": {},
   "source": [
    "We would like to replace this entry with just the names of the genres separated by a comma such as: 'Action, Adventure, Fantasy, Science Fiction' \n",
    "\n",
    "How can we go about this? Since each entry is a JSON string, we could use the json module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca8d56b5-ab29-4049-b4ed-753db9a282c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action', 'Adventure', 'Fantasy', 'Science Fiction']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_obj = json.loads(genres[0])  # Load json string\n",
    "names = [\n",
    "    x[\"name\"] for x in json_obj\n",
    "] \n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156fb96-aaf6-47a5-89e1-d6aa4725182b",
   "metadata": {},
   "source": [
    "We can join lists of words into a string using the join function.\n",
    "\n",
    "```\", \".join(names)```\n",
    "\n",
    "We can easily apply this to the entire Series genres by wrapping everything into a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d4861b1-5ba9-4d68-8221-d16a467d6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Action, Adventure, Fantasy, Science Fiction\n",
       "1                        Adventure, Fantasy, Action\n",
       "2                          Action, Adventure, Crime\n",
       "3                    Action, Crime, Drama, Thriller\n",
       "4                Action, Adventure, Science Fiction\n",
       "                           ...                     \n",
       "4798                        Action, Crime, Thriller\n",
       "4799                                Comedy, Romance\n",
       "4800               Comedy, Drama, Romance, TV Movie\n",
       "4801                                               \n",
       "4802                                    Documentary\n",
       "Name: genres, Length: 4803, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres.map(lambda s: ', '.join(x['name'] for x in json.loads(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be185692-3eff-4758-bc5b-148d4cf1ca73",
   "metadata": {},
   "source": [
    "However, let’s see how we can use the text commands from the last unit to manually extract genres. Let’s start by striping the strings of the square brackets.\n",
    "\n",
    "We put this inside a function because we will keep adding some other functions inside and then we can make a single call to execute them all. For now, let’s see where this version of the function gets us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0bf912f-32f8-4813-b3f4-4192a9b45c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(s):\n",
    "    s = s.str.strip(\"[]\")\n",
    "    return s\n",
    "\n",
    "genres = transform(genres)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd5ddd-e91f-4975-84d8-c6b21f64edbf",
   "metadata": {},
   "source": [
    "So this successfully removed the square brackets. Now we would like to get rid of the other additional characters. We can do this by calling several string replacement functions, one for each sequence of characters that we would like to remove. Let’s give this a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44ae8231-f128-4dc3-983f-86bdbdceb471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 28  Action  12  Adventure  14  Fantasy  878  Science Fiction'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(s):\n",
    "    s = s.str.strip(\"[]\")\n",
    "    s = s.str.replace(\"{\", \"\", regex=True)\n",
    "    s = s.str.replace(\"}\", \"\", regex=True)\n",
    "    s = s.str.replace(\",\", \"\", regex=True)\n",
    "    s = s.str.replace('\"id\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"name\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"', \"\", regex=True)\n",
    "    return s\n",
    "\n",
    "genres = transform(genres)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35249b2a-7c52-4757-b07f-f43ddefb8921",
   "metadata": {},
   "source": [
    "This is now definitely closer to what we wanted. The last challenge is to get rid of the numbers inside the string. But how can we do this? One option would be to use the replace method to remove each digit separately. This is quite tedious but it gets the job done. Let’s give it a try by adding the following lines inside the definition of our function transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "767bb977-740f-4219-a2b2-3dd363a78539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Action    Adventure    Fantasy    Science Fiction'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(s):\n",
    "    s = s.str.strip(\"[]\")\n",
    "    s = s.str.replace(\"{\", \"\", regex=True)\n",
    "    s = s.str.replace(\"}\", \"\", regex=True)\n",
    "    s = s.str.replace(\",\", \"\", regex=True)\n",
    "    s = s.str.replace('\"id\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"name\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"', \"\", regex=True)\n",
    "    s = s.str.replace(\"0\", \"\", regex=True)\n",
    "    s = s.str.replace(\"1\", \"\", regex=True)\n",
    "    s = s.str.replace(\"2\", \"\", regex=True)\n",
    "    s = s.str.replace(\"3\", \"\", regex=True)\n",
    "    s = s.str.replace(\"4\", \"\", regex=True)\n",
    "    s = s.str.replace(\"5\", \"\", regex=True)\n",
    "    s = s.str.replace(\"6\", \"\", regex=True)\n",
    "    s = s.str.replace(\"7\", \"\", regex=True)\n",
    "    s = s.str.replace(\"8\", \"\", regex=True)\n",
    "    s = s.str.replace(\"9\", \"\", regex=True)\n",
    "    return s\n",
    "genres = transform(genres)\n",
    "genres[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25becf-cb58-4dd7-842b-40538695f87c",
   "metadata": {},
   "source": [
    "``` In the following unit, we will learn about regular expressions which enable string matching with less code. For example, instead of removing every digit separately, we can use regular expressions to match all numbers with a single regular expression pattern. Below, we show two alternative approaches to remove digits using regular expressions.\n",
    "\n",
    "1st alternative\n",
    "s = s.str.replace(‘[0-9]+’,’’, regex=True)\n",
    "\n",
    "2nd alternative\n",
    "s = s.str.replace(‘\\d+’,’’, regex=True)\n",
    "\n",
    "Don’t worry if you don’t understand how regular expressions work, as this is the topic of the next unit! ```\n",
    "\n",
    "Almost there! We would like to remove some of the additional white spaces and also make sure to include a comma to separate the entries. There are 3 white spaces in front of the first entry and 4 white spaces separating each of the remaining entries. So what we could do is first replace all blocks of 4 white spaces with a ', ' and then remove the remaining three white spaces at the front. Let’s add the following two cleaning steps in the transform() function.\n",
    "\n",
    "``` Note that the order in which we are adding the functions inside our routine is important since the transformations on the strings are applied in sequential order. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19027414-95ef-4a4a-ad5c-5ee3a113f14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action, Adventure, Fantasy, Science Fiction'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(s):\n",
    "    s = s.str.strip(\"[]\")\n",
    "    s = s.str.replace(\"{\", \"\", regex=True)\n",
    "    s = s.str.replace(\"}\", \"\", regex=True)\n",
    "    s = s.str.replace(\",\", \"\", regex=True)\n",
    "    s = s.str.replace('\"id\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"name\":', \"\", regex=True)\n",
    "    s = s.str.replace('\"', \"\", regex=True)\n",
    "    s = s.str.replace(\"0\", \"\", regex=True)\n",
    "    s = s.str.replace(\"1\", \"\", regex=True)\n",
    "    s = s.str.replace(\"2\", \"\", regex=True)\n",
    "    s = s.str.replace(\"3\", \"\", regex=True)\n",
    "    s = s.str.replace(\"4\", \"\", regex=True)\n",
    "    s = s.str.replace(\"5\", \"\", regex=True)\n",
    "    s = s.str.replace(\"6\", \"\", regex=True)\n",
    "    s = s.str.replace(\"7\", \"\", regex=True)\n",
    "    s = s.str.replace(\"8\", \"\", regex=True)\n",
    "    s = s.str.replace(\"9\", \"\", regex=True)\n",
    "    s = s.str.replace(\"    \", \", \")\n",
    "    s = s.str.replace(\"   \", \"\")\n",
    "    return s\n",
    "genres = transform(genres)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee9628-d55d-4f8c-85c4-975914449945",
   "metadata": {},
   "source": [
    "Exactly what we wanted! To have these changes reflected in the original DataFrame we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9345175c-b287-4cec-ae3d-f9815cced2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Adventure, Fantasy, Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Action, Crime, Drama, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>Fantasy, Action, Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tangled</td>\n",
       "      <td>Animation, Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>Adventure, Fantasy, Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "5                              Spider-Man 3   \n",
       "6                                   Tangled   \n",
       "7                   Avengers: Age of Ultron   \n",
       "8    Harry Potter and the Half-Blood Prince   \n",
       "9        Batman v Superman: Dawn of Justice   \n",
       "\n",
       "                                        genres  \n",
       "0  Action, Adventure, Fantasy, Science Fiction  \n",
       "1                   Adventure, Fantasy, Action  \n",
       "2                     Action, Adventure, Crime  \n",
       "3               Action, Crime, Drama, Thriller  \n",
       "4           Action, Adventure, Science Fiction  \n",
       "5                   Fantasy, Action, Adventure  \n",
       "6                            Animation, Family  \n",
       "7           Action, Adventure, Science Fiction  \n",
       "8                   Adventure, Fantasy, Family  \n",
       "9                   Action, Adventure, Fantasy  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[\"genres\"] = genres\n",
    "movies.loc[:, [\"title\", \"genres\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d18db-9e7b-4d07-8165-417c39cf3a56",
   "metadata": {},
   "source": [
    "## Exercise: further practice with the movies dataset\n",
    "\n",
    "In this unit, you will continue the work with the movies dataset that we saw in the previous units. We saw how to clean up the text of the genres column. Your task is to apply similar transformations to the keywords column. Your task is the following\n",
    "\n",
    "\n",
    "Task: Transform the entries of the column keywords so that they each contain the first 3 keywords separated by a comma.\n",
    "\n",
    "For example the entry :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4623f7a-a937-42b8-98f6-2946f8ecaf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\": 2964, \"name\": \"future\"}, {\"id\": 3386, \"name\": \"space war\"}, {\"id\": 3388, \"name\": \"space colony\"}, {\"id\": 3679, \"name\": \"society\"}, {\"id\": 3801, \"name\": \"space travel\"}, {\"id\": 9685, \"name\": \"futuristic\"}, {\"id\": 9840, \"name\": \"romance\"}, {\"id\": 9882, \"name\": \"space\"}, {\"id\": 9951, \"name\": \"alien\"}, {\"id\": 10148, \"name\": \"tribe\"}, {\"id\": 10158, \"name\": \"alien planet\"}, {\"id\": 10987, \"name\": \"cgi\"}, {\"id\": 11399, \"name\": \"marine\"}, {\"id\": 13065, \"name\": \"soldier\"}, {\"id\": 14643, \"name\": \"battle\"}, {\"id\": 14720, \"name\": \"love affair\"}, {\"id\": 165431, \"name\": \"anti war\"}, {\"id\": 193554, \"name\": \"power relations\"}, {\"id\": 206690, \"name\": \"mind and soul\"}, {\"id\": 209714, \"name\": \"3d\"}]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.keywords[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f023ab-05b0-40d1-9ae9-16c06cefc286",
   "metadata": {},
   "source": [
    "should become : 'culture clash, future, space war'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59c61575-5a66-42f0-aa9f-064b2dc748c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30540\\2858371587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4160\u001b[0m         \"\"\"\n\u001b[1;32m-> 4161\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30540\\2858371587.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(s)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\adsml\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "movies.keywords = movies.keywords.map(lambda s: ', '.join([ x[\"name\"] for x in json.loads(s)][:3]))\n",
    "movies.keywords[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8c4e2-31f4-4899-8e6a-56d0bbc3e7c9",
   "metadata": {},
   "source": [
    "## Regular expressions\n",
    "\n",
    "In the previous units, you saw that we could get quite far with pandas string functions. Even so, repeatedly applying these functions requires a lot of time and energy. This is where regular expressions can be useful. The primary purpose of regular expressions is to save us from writing unnecessary or repetitive code. Also known as RE, regex, or regular patterns, they consist of a sequence of characters and special characters called metacharacters used to match a set of strings. They allow us to sort through and analyze text much easier and more efficiently. Regular expressions first came about in 1956 when Stephen Cole Kleene used them to describe certain models of the human nervous system. Later on, they were used in several text editors, and nowadays, they have far-reaching applications, including in the world of data science.\n",
    "\n",
    "### Our first examples with metacharacters\n",
    "In order to use regular expressions, we must be familiar with some of the basic patterns called metacharacters. Metacharacters allow us to match more complex things than just specific substrings. Let’s look at an example. Suppose we had the following Series of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e14a8e73-f5d0-441f-8362-bdf041242c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series(\n",
    "    [\n",
    "        \"0\",\n",
    "        \"John Wood\",\n",
    "        \"Colin Welsh\",\n",
    "        \"my list\",\n",
    "        \"02456\",\n",
    "        np.nan,\n",
    "        \"HELLO WORLD\",\n",
    "        \"water%\",\n",
    "    ])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892b118-cad9-41da-8c70-0759708cad6e",
   "metadata": {},
   "source": [
    "Suppose we want to check whether each entry contains the string ‘John’. As we already saw, we can do this easily in pandas using the str.contains() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e564bbb1-05ea-43f4-bed0-5fd1f0fae4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25269e25-a346-4248-84ec-9c0042dc7572",
   "metadata": {},
   "source": [
    "This will return a Series of boolean values. However, what if we wanted to check if an entry contains the string ‘John’ or ‘Colin’? How would we do this? Well, we could perform an operation between the two boolean arrays as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9e6e14b-c5f3-4e6f-86a3-5f6af680f0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains(\"John\") | s.str.contains(\"Colin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f27e3-2cda-4762-bbc2-3dcd4a6ae2cc",
   "metadata": {},
   "source": [
    "This would indeed get the job done, but there is an easier way to do this with the help of regular expressions. We can use the metacharacter |, which acts as the “or” operator. Let’s give this a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45490c06-6984-4f59-9e39-e0697d9b00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains(\"John|Colin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa636a-899d-4aa9-a9c2-46faf39e8041",
   "metadata": {},
   "source": [
    "So here, we passed the regular expression directly to the str.contains() function. The nice thing about pandas is that most of the string functions accept regular expressions.\n",
    "\n",
    "Let’s look at a second example.\n",
    "\n",
    "The metacharacter ```.``` matches any character other than a new line. Can you guess the result of the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cecc0519-315b-4676-8a68-fec28379ebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = pd.Series([\"bar\", \"sugar\", \"cartoon\", \"argon\"])\n",
    "s2.str.contains(\".ar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81170e1a-b086-4b03-8307-836a815263a4",
   "metadata": {},
   "source": [
    "Here we are looking for substrings of the type xar, where x can be any character. So, as long as the substring ar is found and there is at least one other character in front of the a, the result will be True. Indeed this is what we get back.\n",
    "\n",
    "### Matching sets of characters\n",
    "Another very common metacharacter is the square brackets []. Inside the brackets, we can specify a set of characters to match. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40502606-3ebc-4f5f-8a5c-210dddd7f5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.str.contains(\"[bc]ar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1eaa2-9d50-44a0-95b4-59c3af7ceb74",
   "metadata": {},
   "source": [
    "will return True if a string contains either the substring bar or car.\n",
    "\n",
    "We can also specify inside the square brackets what kind of characters we want to match as follows:\n",
    "\n",
    "- [a-z] - match any lowercase letter\n",
    "- [A-Z] - match any uppercase letter\n",
    "- [0-9] - match any digit\n",
    "- [a-zA-Z0-9] - match any letter or digit\n",
    "\n",
    "For example, we can search for all strings containing a digit in the string s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59f5c455-078d-466b-877a-fdcb67e96e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s.str.contains(\"[0-9]\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaa7c3-371a-4a63-8a3d-a86140c8213e",
   "metadata": {},
   "source": [
    "Adding the ^ symbol inside the square brackets matches any characters NOT in the set. So we have\n",
    "\n",
    "- [^a-z] - match any character that is not a lowercase letter\n",
    "- [^A-Z] - match any character that is not a uppercase letter\n",
    "- [^0-9] - match any character that is not a digit\n",
    "- [^a-zA-Z0-9] - match any character that is not a letter or digit\n",
    "\n",
    "On top of this, we can use certain shorthand for specifying common sequences:\n",
    "\n",
    "- \\d - match any digit\n",
    "- \\D - match any non-digit\n",
    "- \\w - match any alphanumeric character (letter or digit) or an underscore (_)\n",
    "- \\W - match any character that is not alphanumeric or an underscore as described above\n",
    "- \\s - match whitespace (spaces, tabs, newlines, etc.)\n",
    "- \\S - match non-whitespace\n",
    "\n",
    "Here is then another way to find all strings containing a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ec149de-9d56-44b5-9830-39465ef2995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s.str.contains(\"[\\d]\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766ca7a-2f82-4047-8336-786aba656866",
   "metadata": {},
   "source": [
    "### Matching at the start and end of strings\n",
    "We can also specify the location of the string where we want to match by using:\n",
    "\n",
    "- ^ - match at the beginning of a string\n",
    "- $ - searches for matches at the end of a string\n",
    "\n",
    "We want to search for strings that start with the letter 'b' or 'c' in s2. Then we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "19bc555b-48ee-4088-8b8e-fdbaf63c00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        bar\n",
       "2    cartoon\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[s2.str.contains(\"^[bc]\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893048e5-5015-4245-94b6-9cb79b292bd9",
   "metadata": {},
   "source": [
    "Or we can search for strings that end in 'ar' by writing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c24e0b0-5d33-44a6-9a55-aa77e5b58bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bar\n",
       "1    sugar\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[s2.str.contains(\"ar$\", na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df006e1-9476-49cb-a109-aaebcb20910d",
   "metadata": {},
   "source": [
    "Matching preceding characters\n",
    "Often we want to mention a certain character and then ask to match one or more copies of this character. We can do this using the following metacharacters:\n",
    "\n",
    "- * - match zero or more copies of the preceding character\n",
    "- ? - match zero or 1 copy of the preceding character\n",
    "- + - match 1 or more copies of the preceding character\n",
    "\n",
    "Or we can use curly braces to specify how many times we want to match the given character. We have the following choices:\n",
    "\n",
    "- {m} - match the preceding element m times\n",
    "- {m,} - match the preceding element m times or more\n",
    "- {m,n} - match the preceding element between m and n times\n",
    "\n",
    "Let’s look at one other example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "014e8d51-5219-4758-bfd4-849eb9735b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = pd.Series([\"forest\", \"o\", \"ff\", \"foo\", \"fof\"])\n",
    "s3.str.contains(\"f+o?f+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c268134-531c-4112-b6f6-a5edfbf7f35a",
   "metadata": {},
   "source": [
    "This will search for all strings that contain 1 or more f’s, then an optional o, and finally 1 or more f’s. We can see that the third and fifth strings satisfy this pattern, as shown in the output.\n",
    "\n",
    "An important thing to know is that if a character has a special meaning, we can use a backslash \\ in front of it to “escape” its special meaning. For example, if we want to match periods, we cannot just use . since this will match any character, as we mentioned before. We must use \\. instead.\n",
    "\n",
    "### Grouping\n",
    "Groups are parts of regular expression patterns enclosed in parentheses (e.g. (abc)). We use them to combine smaller regular expressions into larger ones.\n",
    "\n",
    "For example, when used with the str.extract() method, grouping allows extracting captured groups in separate columns in a dataframe. Let’s look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df037041-3ff4-4d3d-8da7-36c78752db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0     Monday\n",
       "1  Wednesday\n",
       "2   Saturday"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = pd.Series([\"Monday5km\", \"Wednesday10km\", \"Saturday25km\"])\n",
    "# Extract weekday names in a new column\n",
    "s4.str.extract(\"(\\w+day)\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0869926-463a-4687-ad69-09304d6d7c69",
   "metadata": {},
   "source": [
    "This returned a new dataframe where the captured groups were stored in a new column. Note that we must use groups every time we use the str.extract() function.\n",
    "\n",
    "What is the difference between the regular expression \\w+day and \\wday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0d5e92e-d7ed-4076-9e54-789959147799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  nday\n",
       "1  sday\n",
       "2  rday"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4.str.extract(\"(\\wday)\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4f79a8b-a9ec-4390-9967-97accadf0cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      NaN\n",
       "1   Sunday\n",
       "2  weekday\n",
       "3   midday"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5=pd.Series(['daylight saving', 'Sunday', 'weekday', 'midday on Saturday'])\n",
    "s5.str.extract('(\\w+day)') # only the first match in each string is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20f5fcbd-27df-4518-a256-e46b93303e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>5km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>25km</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "0     Monday   5km\n",
       "1  Wednesday  10km\n",
       "2   Saturday  25km"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract weekday names and distances in km in separate columns\n",
    "s4.str.extract(\"(\\w+day)(\\d+km)\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b8d74eff-cc60-46b7-acdb-e0c1f0285fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monday5km'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define string sample\n",
    "sample = 'Monday5km'\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d2173-46ea-46c1-b84e-9cae2c9da333",
   "metadata": {},
   "source": [
    "We will use the match function from the re library to match groups in the string sample from above. The function groups returns the matched groups in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "faa22b98-caec-443f-849c-ffc531d45b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Monday', '5km')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import re library\n",
    "import re\n",
    "\n",
    "# Match groups according to regex pattern\n",
    "m = re.match('(\\w+day)(\\d+km)', # regex pattern\n",
    "             sample              # string sample\n",
    "            )\n",
    "\n",
    "# Show matched groups\n",
    "m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93990df8-38ee-49eb-a112-fb5178622fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monday'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first matched group\n",
    "\n",
    "m.groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f3538b6b-cc2f-483b-b5f9-a5f8a73a58c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5km'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.groups()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95071ae5-b2bf-403f-99f6-3dd3798ffb38",
   "metadata": {},
   "source": [
    "In the cell below, we return the first three characters of the first matched group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f68db4e-58fa-46a3-a87e-aaf96a163fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.groups()[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e5c96-b741-4525-b37c-d262e27905de",
   "metadata": {},
   "source": [
    "Let’s practice grouping with a small exercise. We will start from the example where we matched weekday names '\\w+day' in the s4 dataframe. Instead of the full weekday names, we would like to return the abbreviated names: ‘Mon’, ‘Wed’, and ‘Sat’.\n",
    "\n",
    "We first define a function that returns the first three characters in the first matched group, we pass it to thestr.replace() in place of the replacement string as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a05661ae-c9fd-454d-a215-af6327aabbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Mon5km\n",
       "1    Wed10km\n",
       "2    Sat25km\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x.groups()[0][:3]\n",
    "\n",
    "s4.str.replace(\"(\\w+day)\",\n",
    "               f,           \n",
    "               regex=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db5dac-6f34-448a-a088-a70cb91fb466",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "This wraps up our introduction to regular expressions. Of course, this unit only scratches the surface since regular expressions are a vast topic, and entire books have been written about them. Combining the ideas that we covered here should give you enough flexibility for working with text data in pandas. Note that you will have to import the re library whenever you need to use regular expressions outside of pandas.\n",
    "\n",
    "If you’d like to learn more about regular expressions, a good place to start are the following resources:\n",
    "\n",
    "- [Python’s re package Documentation](https://docs.python.org/3/library/re.html)\n",
    "- [Python’s official regular expression HOWTO](https://docs.python.org/3/howto/regex.html)\n",
    "\n",
    "And these webpages allow you to build, test and debug your regular expressions with your own sample texts:\n",
    "\n",
    "- [Regular expressions 101](https://regex101.com/), note you need to set the flavor to Python in the top left panel.\n",
    "- [regexr](https://regexr.com/)\n",
    "- [pythex](https://pythex.org/)\n",
    "\n",
    "In the next unit, you will test your skills by working on a dataset using regular expressions.\n",
    "\n",
    "## 06. Exercise: using regular expressions in pandas\n",
    "\n",
    "In this unit, you will get to practice the regular expression you just learned. You will work with a dataset that contains information about a person’s meals over the last week. The data is stored in a single text file given below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ba1fb9a-00f3-49fc-95ae-adaddf409aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: 9:12am – Omelet,  3:30pm– Apple slices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: 9:35am – Banana bread, 11:00am –Saute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday: 9:00am – Banana pancakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: 7:23pm– Slow cooker pulled pork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: 3:30pm – Can of tuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday: 9:11am: Eggs and sweet potato hash b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday: 11:00am: Meat and veggie stir fry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Monday: 9:12am – Omelet,  3:30pm– Apple slices...\n",
       "1  Tuesday: 9:35am – Banana bread, 11:00am –Saute...\n",
       "2                Wednesday: 9:00am – Banana pancakes\n",
       "3          Thursday: 7:23pm– Slow cooker pulled pork\n",
       "4                       Friday: 3:30pm – Can of tuna\n",
       "5  Saturday: 9:11am: Eggs and sweet potato hash b...\n",
       "6          Sunday: 11:00am: Meat and veggie stir fry"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meal_plan = [\n",
    "    \"Monday: 9:12am – Omelet,  3:30pm– Apple slices with almond butter\",\n",
    "    \"Tuesday: 9:35am – Banana bread, 11:00am –Sauteed veggies, 7:02pm– Taco pie\",\n",
    "    \"Wednesday: 9:00am – Banana pancakes\",\n",
    "    \"Thursday: 7:23pm– Slow cooker pulled pork\",\n",
    "    \"Friday: 3:30pm – Can of tuna\",\n",
    "    \"Saturday: 9:11am: Eggs and sweet potato hash browns, 3:22pm: Almonds\",\n",
    "    \"Sunday: 11:00am: Meat and veggie stir fry\",\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(meal_plan, columns=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287e881-b749-442f-bed7-4a2d0b451475",
   "metadata": {},
   "source": [
    "Your task is to extract all of the times that appear in the strings and store them in a new DataFrame as the one below. \n",
    "\n",
    "***Note:***\n",
    "\n",
    "For the purpose of the exercise we are ignoring the time of the meal and we are always labeling the first meal of the day as breakfast, then lunch and dinner.\n",
    "\n",
    "***Hints:***\n",
    "\n",
    "the method str.extract() extracts only the first occurrence of the match in each string. To extract all occurrences of a match we must use str.extractall().\n",
    "the levels and labels of a MultiIndex can be changed using index.set_levels() and index.set_labels() respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65898c41-bacd-4e00-8045-367e4b7b665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution : \n",
    "\n",
    "sol = df['text'].str.extractall('(\\d?\\d):(\\d\\d)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "153ab8d1-beaa-4ce2-8a23-91fc58f3c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Mon: 9:12am – Omelet,  3:30pm– Apple slices wi...\n",
       "1    Tue: 9:35am – Banana bread, 11:00am –Sauteed v...\n",
       "2                        Wed: 9:00am – Banana pancakes\n",
       "3                 Thu: 7:23pm– Slow cooker pulled pork\n",
       "4                            Fri: 3:30pm – Can of tuna\n",
       "5    Sat: 9:11am: Eggs and sweet potato hash browns...\n",
       "6               Sun: 11:00am: Meat and veggie stir fry\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x.groups()[0][:3]\n",
    "\n",
    "df.text.str.replace(\"(\\w+day)\",\n",
    "               f,           \n",
    "               regex=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "627b82e5-c274-45fa-964d-bb68b7dbf474",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringMethods' object has no attribute 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30540\\3942558905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30540\\3942558905.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StringMethods' object has no attribute 'groups'"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x.groups()[0][:3]\n",
    "\n",
    "f(df.text.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765efb6-ce7c-4551-98c1-4a53e467742e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
